<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="author" content="Thomas Steeples">
    <title>Mean-Payoff Games with ω-Regular Specifications</title>
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/reveal.min.css">
    <link rel="stylesheet" href="css/style.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/js/reveal.min.js" defer></script>
    <script src="js/main.js" defer></script>
    <script type="text/javascript" id="MathJax-script" defer
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <div class="reveal">
        <div class="slides">
            <section>
                <h1 class="title">Mean-Payoff Games with \(\omega\)-Regular Specifications</h1>
                <div class="flex_container">
                    <div class="flex_item">
                        <p class="author">
                            <strong>Thomas Steeples</strong>
                        </p>
                        <p>
                            University of Oxford
                        </p>
                    </div>
                    <div class="flex_item">
                        <p class="author">
                            <strong>Julian Gutierrez</strong>
                        </p>
                        <p>
                            Monash University
                        </p>
                    </div>
                    <div class="flex_item">
                        <p class="author">
                            <strong>Michael Wooldridge</strong>
                        </p>
                        <p>
                            University of Oxford
                        </p>
                    </div>
                </div>
            </section>
            <section>
                <h2>Question:</h2>
                <p>How do we understand the possible behaviours of multi-agent systems?</p>
                <h2>Answer:</h2>
                <p>We treat them as games and analyse them with game theoretic techniques.</p>
            </section>
            <section>
                <h2>The computational model</h2>
                <p>We use concurrent game structures. These consist of:</p>
                <ul>
                    <li>A set of agents and states;</li>
                    <li>The actions the agents can take;</li>
                    <li>The effects of their actions on the states.</li>
                </ul>
            </section>
            <section>
                <h2>Formally:</h2>
                <p>A concurrent game structure, \(M\), is a tuple,
                    \begin{equation*}
                    M = \left(\text{Ag},\text{St},s^0, {(\text{Ac}_i)}_{i \in \text{Ag}}, \text{tr}\right),
                    \end{equation*}
                    where,
                </p>
                <ul>
                    <li>\(\text{Ag}\) and \(\text{St}\) are finite non-empty sets of agents and states respectively;
                    </li>
                    <li>\(s^0 \in \text{St}\) is a start state;</li>
                    <li>For each agent \(i \in \text{Ag}\), \(\text{Ac}_i\) is a set of actions available to player
                        \(i\);
                    </li>
                    <li>\(\text{tr} : \text{St} \times \text{Ac}_1 \times \ldots \times \text{Ac}_{\lvert
                        \text{Ag}\rvert} \to \text{St}\) is the state transition function.</li>
                </ul>
            </section>
            <section>
                <h2>How is the game played?</h2>
                <ul>
                    <li>Start in state \(s^0\);</li>
                    <li>Each agent \(i\) chooses an action, \(\text{ac}_i^0\);</li>
                    <li>The game moves to state \(s^1 = \text{tr}(s^0, \text{ac}_1^0, \ldots, \text{ac}_{\lvert
                        \text{Ag}
                        \rvert}^0)\);</li>
                    <li>Repeat ad infinitum.</li>
                </ul>
                <p>This induces an infinite series of states, \(\pi\), which we call a <em>run</em>.</p>
            </section>
            <section>
                <h2>What about agent preferences?</h2>
                <p>We use weight functions on the states to specify agents' objectives.</p>
                <p>For each agent \(i \in \text{Ag}\), we have a function \(w_i : \text{St} \to \mathbb{Z}\) assigning a
                    weight to each state.</p>
                <p>We then need to assign some sensible value to a run, \(\pi\), given these weights.</p>
            </section>
            <section>
                <h2>Mean-payoff of a run</h2>
                <p>
                    We use the mean-payoff, or limit-average of a run: \begin{equation*}
                    \textsf{mp}_i(\pi) = \liminf_{n
                    \to \infty}
                    \frac{1}{n} \sum_{i=0}^{n-1} w_i(\pi[i])
                    \end{equation*}
                </p>
                <p>Players prefer a higher mean-payoff. </p>
            </section>
            <section>
                <h2>Strategies</h2>
                <p>Strategies dictate how each player should act. Mathematically, they take the form \(\sigma_i:
                    \text{St}^+ \to \text Ac_i\). A strategy profile, \(\vec{\sigma}\), is a tuple consisting of a
                    strategy
                    for each player. This is turn induces a run, \(\pi = \rho(\vec{\sigma})\). </p>
                <p>Two special kinds of strategies: finite-memory strategies and memoryless strategies. We work with
                    unrestricted strategies unless otherwise stated.</p>
            </section>
            <section>
                <h2>An example</h2><canvas id="robot_example_1" height="500px" width="800px"></canvas>
            </section>
            <section>
                <h2>How do we model rational behaviour?</h2>
                <p>We use solution concepts from game theory, such as the Nash equilibrium, and the core:</p>
                <div class="flex_container">
                    <div class="flex_item">
                        <h3>Nash Equilibrium</h3>
                        <p><em>Informally</em>: strategy profiles stable to unilateral deviations.</p>
                        <p><em>Formally</em>: \(\vec{\sigma}\) is a Nash equilibrium if for all players \(i\) and for
                            all
                            strategies \(\sigma_i^\prime\), we have \begin{equation*}\vec{\sigma} \succeq_i
                            (\vec{\sigma}_{-i},
                            \sigma_i^\prime).\end{equation*}</p>
                    </div>
                    <div class="flex_item">
                        <h3>The Core</h3>
                        <p><em>Informally</em>: strategy profiles stable to coalitional deviations.</p>
                        <p><em>Formally</em>: \(\vec{\sigma}\) is in the core if for all coalitions \(C \subseteq
                            \text{Ag}\), and for all strategy vectors \(\vec{\sigma}_C^\prime\), there exists some
                            response, \(\vec{\sigma}_{\text{Ag} \setminus C}^\prime\), and a player \(i\) such that
                            \begin{equation*}\vec{\sigma} \succeq_i (\vec{\sigma}_{\text{Ag} \setminus C}^\prime,
                            \sigma_C^\prime)\end{equation*}
                        </p>
                    </div>
                </div>
            </section>
            <section>
                <h2>Specifying desirable behaviours</h2>
                <p>Obvious answer: use Linear Temporal Logic specifications! </p>
                <p>Label the states with propositional variables, \(\lambda: \text{St} \to 2^{\text{AP}}\), then write
                    specifications in LTL. </p>
                <p>For instance, label safe states with \(\text{SAFE}\), then use the specification \(\textbf{G} \,
                    \text{SAFE}\) (read: always \(\text{SAFE}\)). </p>
                <p>Specifications can be (and usually are!) much more complicated than this.</p>
            </section>
            <section>
                <h2>But…</h2>
                <p>This is computationally expensive!</p>
                <p>The E-NASH problem for mean-payoff games with LTL specifications is PSPACE-complete.</p>
            </section>
            <section>
                <h2>Problem</h2>
                <p>How do we specify desirable properties of the system in a way that is:</p>
                <ul>
                    <li>Expressive?</li>
                    <li>Concise?</li>
                    <li>Computationally tractable?</li>
                </ul>
            </section>
            <section>
                <h2>Answer</h2>
                <p>We use \(\omega\)-regular specifications!</p>
            </section>
            <section>
                <h2>\(\omega\)-regular specifications - syntax</h2>
                <p>Let \(F\) be a set of states, then the grammar of \(\omega\)-regular specifications is given by:
                    \begin{equation*}\alpha
                    ::= \text{Inf}(F) \mid \lnot \alpha \mid \alpha \land \alpha,\end{equation*} where \(F \subseteq
                    \text{St}\) can be
                    any arbitrary subset of the states.</p>
                <p>For notational convenience, we write \(\text{Fin}(F)\) for \(\lnot \text{Inf}(F)\) and
                    \(\text{Inf(!F)}\)
                    for \(\text{Inf}(\text{St} \setminus F)\).</p>
            </section>
            <section>
                <h2>\(\omega\)-regular specifications - semantics</h2>
                <p>Let \(\pi\) be a run, \(F \subseteq \text{St}\), and \(\alpha, \beta\) be arbitrary
                    \(\omega\)-regular
                    specifications. Then,</p>
                <ul>
                    <li>\(\pi \models \text{Inf}(F)\), if \(\text{Inf}(\pi) \cap F \neq \emptyset\);</li>
                    <li>\(\pi \models \lnot \alpha\), if it is not the case that \(\pi \models \alpha\);</li>
                    <li>\(\pi \models \alpha \land \beta\), if \(\pi \models \alpha\) and \(\pi \models \beta\).</li>
                </ul>
            </section>
            <section>
                <h2>\(\omega\)-regular specifications - expressiveness</h2>
                <table>
                    <tr>
                        <th>Traditional winning condition</th>
                        <th>Associated sets</th>
                        <th>\(\omega\)-regular specification</th>
                    </tr>
                    <tr>
                        <td>Büchi </td>
                        <td>\(F \subseteq \text{St}\)</td>
                        <td>\(\text{Inf}(F)\)</td>
                    </tr>
                    <tr>
                        <td>co-Büchi </td>
                        <td>\(G \subseteq \text{St}\) </td>
                        <td>\(\text{Fin}(G)\)</td>
                    </tr>
                    <tr>
                        <td>Generalised Büchi </td>
                        <td>\((F_k)_{k \in K} \subseteq 2^\text{St}\)</td>
                        <td>\(\bigwedge_{k \in K} \text{Inf}(F_k) \)</td>
                    </tr>
                    <tr>
                        <td>Rabin</td>
                        <td>\((L_i, U_i)_{i \in I} \subseteq 2^\text{St} \times 2^\text{St}\) </td>
                        <td>\(\bigvee_{i \in I} \text{Fin}(L_i) \land \text{Inf}(U_i)\)</td>
                    </tr>
                    <tr>
                        <td>Streett </td>
                        <td>\((L_j, U_j)_{j \in J} \subseteq 2^\text{St} \times 2^\text{St}\) </td>
                        <td>\(\bigwedge_{j \in J} \text{Fin}(L_j) \lor \text{Inf}(U_j)\) </td>
                    </tr>
                    <tr>
                        <td>Muller</td>
                        <td>\((F_k)_{k \in K} \subseteq 2^\text{St}\) </td>
                        <td>\(\bigvee_{k \in K} \text{Inf}(F_k) \land \text{Fin}(!F_k)\)</td>
                    </tr>
                </table>
            </section>
            <section>
                <h2>Back to our example</h2>
                <p>So does there exist some Nash equilibrium that satisfies \begin{equation*}\bigwedge_{i \in \text{Ag}}
                    \text{Inf}(P_i) \land \text{Inf}(D_i)?\end{equation*}</p>
            </section>
            <section>
                <h2>Back to our example</h2><canvas id="robot_example_3" height="500px" width="800px"></canvas>
            </section>
            <section>
                <h2>Fundamental decision problems</h2>
                <p>There are two main problems of interest:</p>
                <div class="flex_container">
                    <div class="flex_item">
                        <p><b>MEMBERSHIP</b></p>
                        <p><em>Given:</em> A game \(G\), a strategy profile \(\vec{\sigma}\) and a specification
                            \(\alpha\)
                        </p>
                        <p><em>Question:</em> Is it the case that \(\vec{\sigma} \in \text{NE}(G)\) and
                            \(\rho(\vec{\sigma}) \models \alpha\)?</p>
                    </div>
                    <div class="flex_item">
                        <p><b>E-NASH</b></p>
                        <p><em>Given:</em> A game \(G\) and a specification \(\alpha\)</p>
                        <p><em>Question:</em> Does there exist some \(\vec{\sigma} \in \text{NE}(G)\) such that
                            \(\rho(\vec{\sigma}) \models \alpha\)?</p>
                    </div>
                </div>
            </section>
            <section>
                <h2><b>MEMBERSHIP</b></h2>
                <p><em>Theorem</em>: For memoryless strategies, <b>MEMBERSHIP</b> lies in P.</p>
                <p>Sketch of proof:</p>
                <ol>
                    <li>Calculate each agent's payoff by running the strategy;</li>
                    <li>Use Karp's "maximum mean-weight cycle" algorithm to see if anyone can achieve a higher payoff;
                    </li>
                    <li>Reject if anyone can deviate;</li>
                    <li>Run the strategy to check that \(\alpha\) is satisfied;</li>
                    <li>Accept if it is, reject otherwise;</li>
                </ol>
            </section>
            <section>
                <h2><b>E-NASH</b></h2>
                <p><em>Theorem</em>: <b>E-NASH</b> is NP-complete.</p>
                <p>Sketch of proof:</p>
                <ol>
                    <li>Calculate "punishment values" of game;</li>
                    <li>Prune the game graph accordingly;</li>
                    <li>Form and solve an associated linear program - accept if there exists a solution, reject
                        otherwise;</li>
                    <li>For hardness, reduce from the Hamiltonian cycle problem.</li>
                </ol>
                <p><em>Corollary</em>: If a game has a Nash equilibrium which models the specification, then it also has
                    a finite-memory strategy which models the specification.</p>
            </section>
            <section>
                <h2>The cooperative setting</h2>
                <p>
                    We also showed that for memoryless strategies, core <b>MEMBERSHIP</b> is co-NP-complete and
                    <b>E-CORE</b> lies in \(\Sigma^P_2\).
                </p>
                <p>
                    Deciding the complexity for these problems with arbitrary strategies remains an open problem.
                </p>
            </section>

            <section>
                <h2>Succinct representations</h2>
                <p>Concurrent game structures can be very large.</p>
                <p>The robot example has a transition function of size 429,981,696 - exponential in the size of the
                    agents.
                </p>
                <p>How do we represent these concurrent game structures more succinctly?

                </p>
            </section>

            <section>
                <h2>Succinct representations</h2>
                <p>
                    Using <em>weighted reactive module games</em>, we use propositional variables to encode states and
                    guarded commands to model transitions. With this, the robot example requires 56 variables and 156
                    guarded commands.
                </p>
                <p>
                    In this setting, the <b>E-NASH</b> problem lies in NEXPTIME and is EXPTIME-hard.
                </p>
            </section>

            <section>
                <h2>Conclusion</h2>
                <ul>
                    <li>\(\omega\)-regular specifications are a powerful and concise method of specifying system
                        behaviours;</li>
                    <li>They can be used for any game with an underlying concurrent game structure;</li>
                    <li>These specifications are particularly useful for jointly reasoning about quantitative and
                        qualitative behaviours of a system.</li>
                </ul>
            </section>
        </div>
        <div class="line top"></div>
        <div class="line bottom"></div>
        <div class="line left"></div>
        <div class="line right"></div>
    </div>
</body>

</html>